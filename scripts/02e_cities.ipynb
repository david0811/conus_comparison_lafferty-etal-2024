{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d0c8e4-fa17-4bf8-b6c9-b4b782a4fbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask\n",
    "import gev_bayes_utils as gevbu\n",
    "import gev_city_utils as gevcu\n",
    "import sa_city_utils as sacu\n",
    "import trend_utils as tu\n",
    "\n",
    "from utils import city_list, gev_metric_ids, trend_metric_ids, tgw_scenarios\n",
    "from utils import roar_data_path as project_data_path\n",
    "from utils import roar_code_path as project_code_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d77ddcf-b1e2-4d2e-9e73-8a57e853f5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "### Dask\n",
    "#######################\n",
    "from dask_jobqueue import SLURMCluster\n",
    "\n",
    "cluster = SLURMCluster(\n",
    "    # account=\"open\",\n",
    "    account=\"pches_cr_default\",\n",
    "    queue='basic',\n",
    "    cores=1,\n",
    "    processes=1,\n",
    "    memory=\"3GiB\",\n",
    "    walltime=\"06:00:00\",\n",
    ")\n",
    "\n",
    "cluster.scale(25)\n",
    "\n",
    "from dask.distributed import Client\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74235fbd-a397-449b-9a79-da81bec8e5dc",
   "metadata": {},
   "source": [
    "## Get city timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e54359-9cc2-49a2-9f90-cdd38479f0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for all: extremes\n",
    "for city in city_list.keys():\n",
    "    for metric_id in gev_metric_ids:\n",
    "        sacu.get_city_timeseries_all(city, metric_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bda44b1-e945-49e8-8544-f97311fb14d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for all: extremes with neighbors\n",
    "for city in city_list.keys():\n",
    "    for metric_id in gev_metric_ids:\n",
    "        sacu.get_city_timeseries_all(city, metric_id, include_neighbors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd8eeec-8d8e-41c8-b3e3-7aadca0be50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for all: trends\n",
    "for city in city_list.keys():\n",
    "    for metric_id in trend_metric_ids:\n",
    "        sacu.get_city_timeseries_all(city, metric_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e932cb-4c94-4227-9551-2d5cc729fb79",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Trends with bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c430e59c-668e-4a56-a49f-04de596b766d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit all: cities, bootstrap\n",
    "for city in city_list:\n",
    "    for metric_id in trend_metric_ids:\n",
    "        for n_boot in [250, 1000]:\n",
    "            tu.trend_fit_city(metric_id, city, n_boot=n_boot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9646dc63-3b68-4f5b-9224-7d16073e4e81",
   "metadata": {},
   "source": [
    "## Stationary GEV with bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd36c8f-03c6-48d7-a316-503edb066f4a",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad730f95-d453-47fb-baad-62fccf50510b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main ensemble\n",
    "stationary = True\n",
    "fit_method = \"lmom\"\n",
    "periods_for_level = [10,25,50,100]\n",
    "hist_slice = [1950,2014]\n",
    "proj_slice = [2050,2100]\n",
    "\n",
    "# Loop through all\n",
    "delayed = []\n",
    "\n",
    "for city in city_list:\n",
    "    for metric_id in gev_metric_ids:\n",
    "        for n_boot_proj in [100, 1000]:\n",
    "            delayed.append(dask.delayed(gevcu.fit_ensemble_gev_city)\n",
    "                           (city=city, \n",
    "                            metric_id=metric_id,\n",
    "                            stationary=stationary,\n",
    "                            fit_method=fit_method,\n",
    "                            hist_slice=hist_slice,\n",
    "                            proj_slice=proj_slice,\n",
    "                            n_boot_proj = n_boot_proj,\n",
    "                            periods_for_level=periods_for_level,\n",
    "                            return_samples=True))\n",
    "\n",
    "_ = dask.compute(*delayed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959133b5-42ec-4c68-9246-48dc5371fd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TGW\n",
    "# stationary = True\n",
    "# fit_method = \"lmom\"\n",
    "# periods_for_level = [10,25,50,100]\n",
    "# hist_slice = [1980,2019]\n",
    "# proj_slice = [2049,2099]\n",
    "# return_samples = True\n",
    "# n_boot_hist = 1\n",
    "\n",
    "# stat_str = \"stat\" if stationary else \"nonstat\"\n",
    "# sample_str = \"_samples\" if return_samples else \"\"\n",
    "\n",
    "# df_out = []\n",
    "\n",
    "# for city in city_list:\n",
    "#     for metric_id in gev_metric_ids:\n",
    "#         for ssp in tgw_scenarios[1:]:\n",
    "#             for n_boot_proj in [100, 1000]:\n",
    "#                 # Compute\n",
    "#                 df = gevcu.fit_gev_city(city=city,\n",
    "#                                         metric_id=metric_id,\n",
    "#                                         ensemble='TGW',\n",
    "#                                         gcm='none',\n",
    "#                                         ssp=ssp,\n",
    "#                                         member='none',\n",
    "#                                         fit_method=fit_method,\n",
    "#                                         hist_slice=hist_slice,\n",
    "#                                         proj_slice=proj_slice,\n",
    "#                                         stationary=stationary,\n",
    "#                                         n_boot_proj=n_boot_proj,\n",
    "#                                         n_boot_hist=n_boot_hist,\n",
    "#                                         periods_for_level=periods_for_level,\n",
    "#                                         return_samples=return_samples)\n",
    "#                 # Append\n",
    "#                 df_out.append(df)\n",
    "\n",
    "#         # Store city/metric\n",
    "#         file_name = f\"TGW_{city}_{metric_id}_{hist_slice[0]}-{hist_slice[1]}_{proj_slice[0]}-{proj_slice[1]}_{fit_method}_{stat_str}_nbootproj{n_boot_proj}_nboothist{n_boot_hist}{sample_str}.csv\"\n",
    "#         df_out = pd.concat(df_out, ignore_index=True)\n",
    "#         df_out.to_csv(f\"{project_data_path}/extreme_value/cities/original_grid/freq/{file_name}\", index=False)\n",
    "#         df_out = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c578423-8c67-42fd-8f5d-481b5c5023de",
   "metadata": {},
   "source": [
    "### Naive pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712f3f8c-91f6-4144-92e0-33cbba335c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main ensemble\n",
    "stationary = True\n",
    "fit_method = \"lmom\"\n",
    "periods_for_level = [10,25,50,100]\n",
    "hist_slice = [1950,2014]\n",
    "proj_slice = [2050,2100]\n",
    "\n",
    "# Loop through all\n",
    "delayed = []\n",
    "\n",
    "for city in city_list:\n",
    "    for metric_id in gev_metric_ids:\n",
    "        for n_boot_proj in [100, 1000]:\n",
    "            delayed.append(dask.delayed(gevcu.fit_ensemble_gev_city)\n",
    "                           (city=city, \n",
    "                            metric_id=metric_id,\n",
    "                            stationary=stationary,\n",
    "                            fit_method=fit_method,\n",
    "                            hist_slice=hist_slice,\n",
    "                            proj_slice=proj_slice,\n",
    "                            n_boot_proj = n_boot_proj,\n",
    "                            periods_for_level=periods_for_level,\n",
    "                            return_samples=True,\n",
    "                            include_neighbors=True))\n",
    "\n",
    "_ = dask.compute(*delayed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d271e11-0452-49e5-aef0-a2ebd269c383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TGW\n",
    "stationary = True\n",
    "fit_method = \"lmom\"\n",
    "periods_for_level = [10,25,50,100]\n",
    "hist_slice = [1980,2019]\n",
    "proj_slice = [2049,2099]\n",
    "return_samples = True\n",
    "include_neighbors = True\n",
    "n_boot_hist = 1\n",
    "\n",
    "stat_str = \"stat\" if stationary else \"nonstat\"\n",
    "sample_str = \"_samples\" if return_samples else \"\"\n",
    "neighbor_str = \"_neighbors\" if include_neighbors else \"\"\n",
    "\n",
    "df_out = []\n",
    "\n",
    "for city in city_list:\n",
    "    for metric_id in gev_metric_ids:\n",
    "        for ssp in tgw_scenarios[1:]:\n",
    "            for n_boot_proj in [100, 1000]:\n",
    "                # Compute\n",
    "                df = gevcu.fit_gev_city(city=city,\n",
    "                                        metric_id=metric_id,\n",
    "                                        ensemble='TGW',\n",
    "                                        gcm='none',\n",
    "                                        ssp=ssp,\n",
    "                                        member='none',\n",
    "                                        fit_method=fit_method,\n",
    "                                        hist_slice=hist_slice,\n",
    "                                        proj_slice=proj_slice,\n",
    "                                        stationary=stationary,\n",
    "                                        n_boot_proj=n_boot_proj,\n",
    "                                        n_boot_hist=n_boot_hist,\n",
    "                                        periods_for_level=periods_for_level,\n",
    "                                        return_samples=return_samples,\n",
    "                                        include_neighbors=include_neighbors)\n",
    "                # Append\n",
    "                df_out.append(df)\n",
    "\n",
    "        # Store city/metric\n",
    "        file_name = f\"TGW_{city}_{metric_id}_{hist_slice[0]}-{hist_slice[1]}_{proj_slice[0]}-{proj_slice[1]}_{fit_method}_{stat_str}_nbootproj{n_boot_proj}_nboothist{n_boot_hist}{sample_str}{neighbor_str}.csv\"\n",
    "        df_out = pd.concat(df_out, ignore_index=True)\n",
    "        df_out.to_csv(f\"{project_data_path}/extreme_value/cities/original_grid/freq/{file_name}\", index=False)\n",
    "        df_out = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd19cca3-83cb-4ba2-93f7-96bb83492251",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Non-stationary GEV with bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28beb791-1f58-4252-9978-582287642211",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Location trend only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0bf6ec-4bd3-4e97-a5d2-05a4234f18e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main ensemble: location trend only\n",
    "fit_method = 'mle'\n",
    "stationary = False\n",
    "# n_boots = [100, 1000]\n",
    "n_boots = [100]\n",
    "\n",
    "# Loop through all\n",
    "delayed = []\n",
    "\n",
    "for city in city_list:\n",
    "    for metric_id in gev_metric_ids:\n",
    "        for n_boot in n_boots:\n",
    "            delayed.append(dask.delayed(gevcu.fit_ensemble_gev_city)\n",
    "                           (city=city, \n",
    "                            metric_id=metric_id,\n",
    "                            stationary=stationary,\n",
    "                            fit_method=fit_method,\n",
    "                            n_boot_proj = n_boot,\n",
    "                            return_samples = True))\n",
    "\n",
    "_ = dask.compute(*delayed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a1ac98-9519-4246-ad15-f43cb62591cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TGW\n",
    "stationary = False\n",
    "fit_method = \"mle\"\n",
    "periods_for_level = [10,25,50,100]\n",
    "years = [1980, 2099]\n",
    "return_samples = True\n",
    "n_boot_hist = 1\n",
    "\n",
    "stat_str = \"stat\" if stationary else \"nonstat\"\n",
    "sample_str = \"_samples\" if return_samples else \"\"\n",
    "\n",
    "df_out = []\n",
    "\n",
    "for city in city_list:\n",
    "    for metric_id in gev_metric_ids:\n",
    "        for ssp in tgw_scenarios[1:]:\n",
    "            for n_boot_proj in [100, 1000]:\n",
    "                # Compute\n",
    "                df = gevcu.fit_gev_city(city=city,\n",
    "                                        metric_id=metric_id,\n",
    "                                        ensemble='TGW',\n",
    "                                        gcm='none',\n",
    "                                        ssp=ssp,\n",
    "                                        member='none',\n",
    "                                        fit_method=fit_method,\n",
    "                                        years=years,\n",
    "                                        stationary=stationary,\n",
    "                                        n_boot_proj=n_boot_proj,\n",
    "                                        periods_for_level=periods_for_level,\n",
    "                                        return_samples=return_samples)\n",
    "                # Append\n",
    "                df_out.append(df)\n",
    "\n",
    "        # Store city/metric\n",
    "        file_name = f\"TGW_{city}_{metric_id}_{years[0]}-{years[1]}_{fit_method}_{stat_str}_nboot{n_boot_proj}{sample_str}.csv\"\n",
    "        df_out = pd.concat(df_out, ignore_index=True)\n",
    "        df_out.to_csv(f\"{project_data_path}/extreme_value/cities/original_grid/freq/{file_name}\", index=False)\n",
    "        df_out = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70357349-a6d4-4a70-8ddb-ba21297b1f9c",
   "metadata": {},
   "source": [
    "### Location & scale trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d771c83-c21a-4a3d-8ba1-5176b2f7b6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main ensemble\n",
    "fit_method = 'mle'\n",
    "stationary = False\n",
    "n_boots = [100, 1000]\n",
    "nonstationary_scale = True\n",
    "\n",
    "# Loop through all\n",
    "delayed = []\n",
    "\n",
    "for city in city_list.keys():\n",
    "    for metric_id in gev_metric_ids[:3]:\n",
    "        for n_boot in n_boots:\n",
    "            delayed.append(dask.delayed(gevcu.fit_ensemble_gev_city)\n",
    "                           (city=city, \n",
    "                            metric_id=metric_id,\n",
    "                            stationary=stationary,\n",
    "                            fit_method=fit_method,\n",
    "                            n_boot_proj = n_boot,\n",
    "                            return_samples = True,\n",
    "                            nonstationary_scale = nonstationary_scale))\n",
    "\n",
    "_ = dask.compute(*delayed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec6a25b-4633-467b-8456-bc6563ef6305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TGW\n",
    "# stationary = False\n",
    "# nonstationary_scale = True\n",
    "# fit_method = \"mle\"\n",
    "# periods_for_level = [10,25,50,100]\n",
    "# years = [1980, 2099]\n",
    "# return_samples = True\n",
    "# n_boot_hist = 1\n",
    "\n",
    "# stat_str = \"stat\" if stationary else \"nonstat\"\n",
    "# sample_str = \"_samples\" if return_samples else \"\"\n",
    "# scale_str = \"_scale\" if nonstationary_scale else \"\"\n",
    "\n",
    "# df_out = []\n",
    "\n",
    "# for city in city_list:\n",
    "#     for metric_id in gev_metric_ids:\n",
    "#         for ssp in tgw_scenarios[1:]:\n",
    "#             for n_boot_proj in [100, 1000]:\n",
    "#                 # Compute\n",
    "#                 df = gevcu.fit_gev_city(city=city,\n",
    "#                                         metric_id=metric_id,\n",
    "#                                         ensemble='TGW',\n",
    "#                                         gcm='none',\n",
    "#                                         ssp=ssp,\n",
    "#                                         member='none',\n",
    "#                                         fit_method=fit_method,\n",
    "#                                         years=years,\n",
    "#                                         stationary=stationary,\n",
    "#                                         n_boot_proj=n_boot_proj,\n",
    "#                                         periods_for_level=periods_for_level,\n",
    "#                                         nonstationary_scale=nonstationary_scale,\n",
    "#                                         return_samples=return_samples)\n",
    "#                 # Append\n",
    "#                 df_out.append(df)\n",
    "\n",
    "#         # Store city/metric\n",
    "#         file_name = f\"TGW_{city}_{metric_id}_{years[0]}-{years[1]}_{fit_method}_{stat_str}_nboot{n_boot_proj}{sample_str}{scale_str}.csv\"\n",
    "#         df_out = pd.concat(df_out, ignore_index=True)\n",
    "#         df_out.to_csv(f\"{project_data_path}/extreme_value/cities/original_grid/freq/{file_name}\", index=False)\n",
    "#         df_out = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e44965b-c6d9-4ea6-998d-d06252293c05",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Bayesian GEV (old!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809ed003-bdb1-4a60-bed8-812a88a5f0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For Bayes\n",
    "# ############\n",
    "# ### Dask ###\n",
    "# ############\n",
    "# from dask_jobqueue import SLURMCluster\n",
    "\n",
    "# cluster = SLURMCluster(\n",
    "#     # account=\"pches\",\n",
    "#     account=\"open\",\n",
    "#     cores=3,\n",
    "#     processes=1,\n",
    "#     job_cpu=3,\n",
    "#     memory=\"3GiB\",\n",
    "#     walltime=\"12:00:00\",\n",
    "#     job_script_prologue=[\n",
    "#         f\"export PYTHONPATH={project_code_path}/.venv/lib/python3.12/site-packages:$PYTHONPATH\",  # Put venv first\n",
    "#         \"export JAX_PLATFORM_NAME=cpu\",\n",
    "#         \"export XLA_FLAGS='--xla_force_host_platform_device_count=1'\",\n",
    "#         # Force PyTensor to not use caching at all\n",
    "#         \"export PYTENSOR_FLAGS='cxx=,\",\n",
    "#         \"mode=FAST_COMPILE,\",  # Less aggressive optimization but more stable\n",
    "#         \"allow_gc=True,\",\n",
    "#         \"cache_size=0'\"        # Disable caching completely\n",
    "#     ],\n",
    "#     death_timeout=60,\n",
    "#     local_directory=\"/tmp\"\n",
    "# )\n",
    "\n",
    "# cluster.scale(5)\n",
    "\n",
    "# from dask.distributed import Client\n",
    "# client = Client(cluster)\n",
    "# client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf19267-0c3b-435c-bef8-d46e065c55e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Fit info: non-stationary\n",
    "# future_years = [2015,2100]\n",
    "# stationary = False\n",
    "# return_periods = [100]\n",
    "\n",
    "# # Parallelize with dask delayed\n",
    "# delayed = []\n",
    "\n",
    "# # Loop thorugh all combos\n",
    "# for city in city_list.keys():\n",
    "#     for metric_id in gev_metric_ids:\n",
    "#         tmp = dask.delayed(gevbu.fit_bayesian_gev_ensemble)(\n",
    "#             city=city,\n",
    "#             metric_id=metric_id,\n",
    "#             years=future_years,\n",
    "#             stationary=stationary,\n",
    "#             shape_sigma=0.2,\n",
    "#             prior_identifier='shape_sigma_02',\n",
    "#             return_periods=return_periods,\n",
    "#         )\n",
    "#         delayed.append(tmp)\n",
    "\n",
    "# _ = dask.compute(*delayed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a006b6-79fb-46cd-a127-632558337d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Fit info: stationary\n",
    "# hist_years = [1950,2014]\n",
    "# future_years = [2050,2100]\n",
    "# stationary = True\n",
    "# return_periods = [100]\n",
    "\n",
    "# # Parallelize with dask delayed\n",
    "# delayed = []\n",
    "\n",
    "# # Loop thorugh all combos\n",
    "# for city in city_list.keys():\n",
    "#     for metric_id in gev_metric_ids:\n",
    "#         for years in [hist_years, future_years]:\n",
    "#             tmp = dask.delayed(gevbu.fit_bayesian_gev_ensemble)(\n",
    "#                     city=city,\n",
    "#                     metric_id=metric_id,\n",
    "#                     years=years,\n",
    "#                     stationary=stationary,\n",
    "#                     return_periods=return_periods,\n",
    "#                     dask=False\n",
    "#             )\n",
    "#             delayed.append(tmp)\n",
    "\n",
    "# _ = dask.compute(*delayed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da998a0-fb89-4e4a-9c1c-3364bfcb9e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Loop thorugh all combos and store\n",
    "# store_path = f\"{project_data_path}/extreme_value/cities/original_grid/bayes_combined/\"\n",
    "\n",
    "# return_periods = [100]\n",
    "\n",
    "# prior_identifier = \"shape_sigma_02\"\n",
    "\n",
    "# stationary = False\n",
    "# stationary_string = \"stat\" if stationary else \"nonstat\"\n",
    "\n",
    "# # for city in city_list.keys():\n",
    "# for city in ['nyc', 'chicago', 'denver']:\n",
    "#     for metric_id in ['max_tasmax', 'max_pr', 'min_tasmin']:\n",
    "#     # for metric_id in gev_metric_ids:\n",
    "#         for years in [None, [2015,2100]]:\n",
    "#             # Check if done\n",
    "#             change_identifier = \"\" if years is None else f\"_change_{years[0]}-{years[1]}\"\n",
    "#             file_path = f\"{store_path}/{city}_{metric_id}_{stationary_string}_{prior_identifier}{change_identifier}.csv\"\n",
    "#             if os.path.exists(file_path):\n",
    "#                 continue\n",
    "#             # Read\n",
    "#             df = gevbu.gather_bayesian_gev_results_all(\n",
    "#                 city = city,\n",
    "#                 metric_id = metric_id,\n",
    "#                 return_periods = return_periods,\n",
    "#                 stationary = stationary,\n",
    "#                 prior_identifier = prior_identifier,\n",
    "#                 years = years,\n",
    "#             )\n",
    "#             # Store\n",
    "#             df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417d30a0-9223-4810-88a7-61dad1926833",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
