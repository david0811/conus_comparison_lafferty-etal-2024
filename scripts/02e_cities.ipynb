{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9d0c8e4-fa17-4bf8-b6c9-b4b782a4fbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (pytensor.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask\n",
    "import gev_bayes_utils as gevbu\n",
    "import gev_city_utils as gevcu\n",
    "import sa_city_utils as sacu\n",
    "import trend_utils as tu\n",
    "\n",
    "from utils import city_list, gev_metric_ids, trend_metric_ids, tgw_scenarios\n",
    "from utils import roar_data_path as project_data_path\n",
    "from utils import roar_code_path as project_code_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eaa83df-abca-4e08-b4f0-1becc407addb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #######################\n",
    "# ### Dask\n",
    "# #######################\n",
    "# from dask_jobqueue import SLURMCluster\n",
    "\n",
    "# cluster = SLURMCluster(\n",
    "#     # account=\"open\",\n",
    "#     account=\"pches_cr_default\",\n",
    "#     queue='basic',\n",
    "#     cores=1,\n",
    "#     processes=1,\n",
    "#     memory=\"5GiB\",\n",
    "#     walltime=\"02:00:00\",\n",
    "# )\n",
    "\n",
    "# cluster.scale(10)\n",
    "\n",
    "# from dask.distributed import Client\n",
    "# client = Client(cluster)\n",
    "# client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74235fbd-a397-449b-9a79-da81bec8e5dc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Get city timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4e54359-9cc2-49a2-9f90-cdd38479f0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for all: extremes\n",
    "for city in city_list.keys():\n",
    "    for metric_id in gev_metric_ids:\n",
    "        sacu.get_city_timeseries_all(city, metric_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bda44b1-e945-49e8-8544-f97311fb14d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for all: extremes with neighbors\n",
    "for city in city_list.keys():\n",
    "    for metric_id in gev_metric_ids:\n",
    "        sacu.get_city_timeseries_all(city, metric_id, include_neighbors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6296af0e-5ba4-4c0c-a9ba-4a5e1ee83ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for all: trends\n",
    "for city in city_list.keys():\n",
    "    for metric_id in trend_metric_ids:\n",
    "        sacu.get_city_timeseries_all(city, metric_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e932cb-4c94-4227-9551-2d5cc729fb79",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Trends with bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c430e59c-668e-4a56-a49f-04de596b766d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit all: cities, bootstrap\n",
    "for city in city_list:\n",
    "    for metric_id in trend_metric_ids:\n",
    "        for n_boot in [250, 1000]:\n",
    "            tu.trend_fit_city(metric_id, city, n_boot=n_boot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9646dc63-3b68-4f5b-9224-7d16073e4e81",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Stationary GEV with bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd36c8f-03c6-48d7-a316-503edb066f4a",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad730f95-d453-47fb-baad-62fccf50510b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main ensemble\n",
    "stationary = True\n",
    "fit_method = \"lmom\"\n",
    "periods_for_level = [10,25,50,100]\n",
    "hist_slice = [1950,2014]\n",
    "proj_slice = [2050,2100]\n",
    "\n",
    "# Loop through all\n",
    "delayed = []\n",
    "\n",
    "for city in city_list:\n",
    "    for metric_id in gev_metric_ids:\n",
    "        for n_boot_proj in [100, 1000]:\n",
    "            delayed.append(dask.delayed(gevcu.fit_ensemble_gev_city)\n",
    "                           (city=city, \n",
    "                            metric_id=metric_id,\n",
    "                            stationary=stationary,\n",
    "                            fit_method=fit_method,\n",
    "                            hist_slice=hist_slice,\n",
    "                            proj_slice=proj_slice,\n",
    "                            n_boot_proj = n_boot_proj,\n",
    "                            periods_for_level=periods_for_level,\n",
    "                            return_samples=True))\n",
    "\n",
    "_ = dask.compute(*delayed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "959133b5-42ec-4c68-9246-48dc5371fd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TGW\n",
    "stationary = True\n",
    "fit_method = \"lmom\"\n",
    "periods_for_level = [10,25,50,100]\n",
    "hist_slice = [1980,2019]\n",
    "proj_slice = [2049,2099]\n",
    "return_samples = True\n",
    "n_boot_hist = 1\n",
    "\n",
    "stat_str = \"stat\" if stationary else \"nonstat\"\n",
    "sample_str = \"_samples\" if return_samples else \"\"\n",
    "\n",
    "df_out = []\n",
    "\n",
    "for city in city_list:\n",
    "    for metric_id in gev_metric_ids:\n",
    "        for ssp in tgw_scenarios[1:]:\n",
    "            for n_boot_proj in [100, 1000]:\n",
    "                # Compute\n",
    "                df = gevcu.fit_gev_city(city=city,\n",
    "                                        metric_id=metric_id,\n",
    "                                        ensemble='TGW',\n",
    "                                        gcm='none',\n",
    "                                        ssp=ssp,\n",
    "                                        member='none',\n",
    "                                        fit_method=fit_method,\n",
    "                                        hist_slice=hist_slice,\n",
    "                                        proj_slice=proj_slice,\n",
    "                                        stationary=stationary,\n",
    "                                        n_boot_proj=n_boot_proj,\n",
    "                                        n_boot_hist=n_boot_hist,\n",
    "                                        periods_for_level=periods_for_level,\n",
    "                                        return_samples=return_samples)\n",
    "                # Append\n",
    "                df_out.append(df)\n",
    "\n",
    "        # Store city/metric\n",
    "        file_name = f\"TGW_{city}_{metric_id}_{hist_slice[0]}-{hist_slice[1]}_{proj_slice[0]}-{proj_slice[1]}_{fit_method}_{stat_str}_nbootproj{n_boot_proj}_nboothist{n_boot_hist}{sample_str}.csv\"\n",
    "        df_out = pd.concat(df_out, ignore_index=True)\n",
    "        df_out.to_csv(f\"{project_data_path}/extreme_value/cities/original_grid/freq/{file_name}\", index=False)\n",
    "        df_out = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c578423-8c67-42fd-8f5d-481b5c5023de",
   "metadata": {},
   "source": [
    "### Naive pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "712f3f8c-91f6-4144-92e0-33cbba335c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main ensemble\n",
    "stationary = True\n",
    "fit_method = \"lmom\"\n",
    "periods_for_level = [10,25,50,100]\n",
    "hist_slice = [1950,2014]\n",
    "proj_slice = [2050,2100]\n",
    "\n",
    "# Loop through all\n",
    "delayed = []\n",
    "\n",
    "for city in city_list:\n",
    "    for metric_id in gev_metric_ids:\n",
    "        for n_boot_proj in [100, 1000]:\n",
    "            delayed.append(dask.delayed(gevcu.fit_ensemble_gev_city)\n",
    "                           (city=city, \n",
    "                            metric_id=metric_id,\n",
    "                            stationary=stationary,\n",
    "                            fit_method=fit_method,\n",
    "                            hist_slice=hist_slice,\n",
    "                            proj_slice=proj_slice,\n",
    "                            n_boot_proj = n_boot_proj,\n",
    "                            periods_for_level=periods_for_level,\n",
    "                            return_samples=True,\n",
    "                            include_neighbors=True))\n",
    "\n",
    "_ = dask.compute(*delayed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d271e11-0452-49e5-aef0-a2ebd269c383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TGW\n",
    "stationary = True\n",
    "fit_method = \"lmom\"\n",
    "periods_for_level = [10,25,50,100]\n",
    "hist_slice = [1980,2019]\n",
    "proj_slice = [2049,2099]\n",
    "return_samples = True\n",
    "include_neighbors = True\n",
    "n_boot_hist = 1\n",
    "\n",
    "stat_str = \"stat\" if stationary else \"nonstat\"\n",
    "sample_str = \"_samples\" if return_samples else \"\"\n",
    "neighbor_str = \"_neighbors\" if include_neighbors else \"\"\n",
    "\n",
    "df_out = []\n",
    "\n",
    "for city in city_list:\n",
    "    for metric_id in gev_metric_ids:\n",
    "        for ssp in tgw_scenarios[1:]:\n",
    "            for n_boot_proj in [100, 1000]:\n",
    "                # Compute\n",
    "                df = gevcu.fit_gev_city(city=city,\n",
    "                                        metric_id=metric_id,\n",
    "                                        ensemble='TGW',\n",
    "                                        gcm='none',\n",
    "                                        ssp=ssp,\n",
    "                                        member='none',\n",
    "                                        fit_method=fit_method,\n",
    "                                        hist_slice=hist_slice,\n",
    "                                        proj_slice=proj_slice,\n",
    "                                        stationary=stationary,\n",
    "                                        n_boot_proj=n_boot_proj,\n",
    "                                        n_boot_hist=n_boot_hist,\n",
    "                                        periods_for_level=periods_for_level,\n",
    "                                        return_samples=return_samples,\n",
    "                                        include_neighbors=include_neighbors)\n",
    "                # Append\n",
    "                df_out.append(df)\n",
    "\n",
    "        # Store city/metric\n",
    "        file_name = f\"TGW_{city}_{metric_id}_{hist_slice[0]}-{hist_slice[1]}_{proj_slice[0]}-{proj_slice[1]}_{fit_method}_{stat_str}_nbootproj{n_boot_proj}_nboothist{n_boot_hist}{sample_str}{neighbor_str}.csv\"\n",
    "        df_out = pd.concat(df_out, ignore_index=True)\n",
    "        df_out.to_csv(f\"{project_data_path}/extreme_value/cities/original_grid/freq/{file_name}\", index=False)\n",
    "        df_out = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd19cca3-83cb-4ba2-93f7-96bb83492251",
   "metadata": {},
   "source": [
    "## Non-stationary GEV with bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28beb791-1f58-4252-9978-582287642211",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Location trend only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a0bf6ec-4bd3-4e97-a5d2-05a4234f18e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main ensemble: location trend only\n",
    "fit_method = 'mle'\n",
    "stationary = False\n",
    "# n_boots = [100, 1000]\n",
    "n_boots = [100]\n",
    "\n",
    "# Loop through all\n",
    "delayed = []\n",
    "\n",
    "for city in city_list:\n",
    "    for metric_id in gev_metric_ids:\n",
    "        for n_boot in n_boots:\n",
    "            delayed.append(dask.delayed(gevcu.fit_ensemble_gev_city)\n",
    "                           (city=city, \n",
    "                            metric_id=metric_id,\n",
    "                            stationary=stationary,\n",
    "                            fit_method=fit_method,\n",
    "                            n_boot_proj = n_boot,\n",
    "                            return_samples = True))\n",
    "\n",
    "_ = dask.compute(*delayed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "56a1ac98-9519-4246-ad15-f43cb62591cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TGW\n",
    "stationary = False\n",
    "fit_method = \"mle\"\n",
    "periods_for_level = [10,25,50,100]\n",
    "years = [1980, 2099]\n",
    "return_samples = True\n",
    "n_boot_hist = 1\n",
    "\n",
    "stat_str = \"stat\" if stationary else \"nonstat\"\n",
    "sample_str = \"_samples\" if return_samples else \"\"\n",
    "\n",
    "df_out = []\n",
    "\n",
    "for city in city_list:\n",
    "    for metric_id in gev_metric_ids:\n",
    "        for ssp in tgw_scenarios[1:]:\n",
    "            for n_boot_proj in [100, 1000]:\n",
    "                # Compute\n",
    "                df = gevcu.fit_gev_city(city=city,\n",
    "                                        metric_id=metric_id,\n",
    "                                        ensemble='TGW',\n",
    "                                        gcm='none',\n",
    "                                        ssp=ssp,\n",
    "                                        member='none',\n",
    "                                        fit_method=fit_method,\n",
    "                                        years=years,\n",
    "                                        stationary=stationary,\n",
    "                                        n_boot_proj=n_boot_proj,\n",
    "                                        periods_for_level=periods_for_level,\n",
    "                                        return_samples=return_samples)\n",
    "                # Append\n",
    "                df_out.append(df)\n",
    "\n",
    "        # Store city/metric\n",
    "        file_name = f\"TGW_{city}_{metric_id}_{years[0]}-{years[1]}_{fit_method}_{stat_str}_nboot{n_boot_proj}{sample_str}.csv\"\n",
    "        df_out = pd.concat(df_out, ignore_index=True)\n",
    "        df_out.to_csv(f\"{project_data_path}/extreme_value/cities/original_grid/freq/{file_name}\", index=False)\n",
    "        df_out = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70357349-a6d4-4a70-8ddb-ba21297b1f9c",
   "metadata": {},
   "source": [
    "### Location & scale trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d771c83-c21a-4a3d-8ba1-5176b2f7b6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main ensemble\n",
    "fit_method = 'mle'\n",
    "stationary = False\n",
    "# n_boots = [100, 1000]\n",
    "n_boots = [100]\n",
    "nonstationary_scale = True\n",
    "\n",
    "# Loop through all\n",
    "delayed = []\n",
    "\n",
    "for city in city_list:\n",
    "    for metric_id in gev_metric_ids:\n",
    "        for n_boot in n_boots:\n",
    "            delayed.append(dask.delayed(gevcu.fit_ensemble_gev_city)\n",
    "                           (city=city, \n",
    "                            metric_id=metric_id,\n",
    "                            stationary=stationary,\n",
    "                            fit_method=fit_method,\n",
    "                            n_boot_proj = n_boot,\n",
    "                            return_samples = True,\n",
    "                            nonstationary_scale = nonstationary_scale))\n",
    "\n",
    "_ = dask.compute(*delayed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec6a25b-4633-467b-8456-bc6563ef6305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TGW\n",
    "stationary = False\n",
    "nonstationary_scale = True\n",
    "fit_method = \"mle\"\n",
    "periods_for_level = [10,25,50,100]\n",
    "years = [1980, 2099]\n",
    "return_samples = True\n",
    "n_boot_hist = 1\n",
    "\n",
    "stat_str = \"stat\" if stationary else \"nonstat\"\n",
    "sample_str = \"_samples\" if return_samples else \"\"\n",
    "scale_str = \"_scale\" if nonstationary_scale else \"\"\n",
    "\n",
    "df_out = []\n",
    "\n",
    "for city in city_list:\n",
    "    for metric_id in gev_metric_ids:\n",
    "        for ssp in tgw_scenarios[1:]:\n",
    "            for n_boot_proj in [100, 1000]:\n",
    "                # Compute\n",
    "                df = gevcu.fit_gev_city(city=city,\n",
    "                                        metric_id=metric_id,\n",
    "                                        ensemble='TGW',\n",
    "                                        gcm='none',\n",
    "                                        ssp=ssp,\n",
    "                                        member='none',\n",
    "                                        fit_method=fit_method,\n",
    "                                        years=years,\n",
    "                                        stationary=stationary,\n",
    "                                        n_boot_proj=n_boot_proj,\n",
    "                                        periods_for_level=periods_for_level,\n",
    "                                        nonstationary_scale=nonstationary_scale,\n",
    "                                        return_samples=return_samples)\n",
    "                # Append\n",
    "                df_out.append(df)\n",
    "\n",
    "        # Store city/metric\n",
    "        file_name = f\"TGW_{city}_{metric_id}_{years[0]}-{years[1]}_{fit_method}_{stat_str}_nboot{n_boot_proj}{sample_str}{scale_str}.csv\"\n",
    "        df_out = pd.concat(df_out, ignore_index=True)\n",
    "        df_out.to_csv(f\"{project_data_path}/extreme_value/cities/original_grid/freq/{file_name}\", index=False)\n",
    "        df_out = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aae0733f-4c7d-4c70-9616-39a053dbe7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quantile</th>\n",
       "      <th>ensemble</th>\n",
       "      <th>gcm</th>\n",
       "      <th>member</th>\n",
       "      <th>ssp</th>\n",
       "      <th>loc_intcp</th>\n",
       "      <th>loc_trend</th>\n",
       "      <th>log_scale_intcp</th>\n",
       "      <th>log_scale_trend</th>\n",
       "      <th>shape</th>\n",
       "      <th>...</th>\n",
       "      <th>100yr_return_level_2075</th>\n",
       "      <th>100yr_return_level_2100</th>\n",
       "      <th>10yr_return_level_diff_2075-1975</th>\n",
       "      <th>25yr_return_level_diff_2075-1975</th>\n",
       "      <th>50yr_return_level_diff_2075-1975</th>\n",
       "      <th>100yr_return_level_diff_2075-1975</th>\n",
       "      <th>10yr_return_level_chfc_2075-1975</th>\n",
       "      <th>25yr_return_level_chfc_2075-1975</th>\n",
       "      <th>50yr_return_level_chfc_2075-1975</th>\n",
       "      <th>100yr_return_level_chfc_2075-1975</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>main</td>\n",
       "      <td>LOCA2</td>\n",
       "      <td>CanESM5</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>ssp585</td>\n",
       "      <td>57.742605</td>\n",
       "      <td>0.091815</td>\n",
       "      <td>2.893627</td>\n",
       "      <td>0.001578</td>\n",
       "      <td>-0.226628</td>\n",
       "      <td>...</td>\n",
       "      <td>247.453835</td>\n",
       "      <td>256.920751</td>\n",
       "      <td>18.607240</td>\n",
       "      <td>24.262965</td>\n",
       "      <td>29.317828</td>\n",
       "      <td>35.198942</td>\n",
       "      <td>1.161544</td>\n",
       "      <td>1.163637</td>\n",
       "      <td>1.164849</td>\n",
       "      <td>1.165833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>q025</td>\n",
       "      <td>LOCA2</td>\n",
       "      <td>CanESM5</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>ssp585</td>\n",
       "      <td>52.820643</td>\n",
       "      <td>0.015332</td>\n",
       "      <td>2.542673</td>\n",
       "      <td>-0.001818</td>\n",
       "      <td>-0.386558</td>\n",
       "      <td>...</td>\n",
       "      <td>190.025593</td>\n",
       "      <td>189.973425</td>\n",
       "      <td>-8.186143</td>\n",
       "      <td>-14.267087</td>\n",
       "      <td>-19.828523</td>\n",
       "      <td>-25.490894</td>\n",
       "      <td>0.934852</td>\n",
       "      <td>0.914075</td>\n",
       "      <td>0.902574</td>\n",
       "      <td>0.893399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>q975</td>\n",
       "      <td>LOCA2</td>\n",
       "      <td>CanESM5</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>ssp585</td>\n",
       "      <td>63.460247</td>\n",
       "      <td>0.165027</td>\n",
       "      <td>3.173491</td>\n",
       "      <td>0.004790</td>\n",
       "      <td>-0.125098</td>\n",
       "      <td>...</td>\n",
       "      <td>374.709258</td>\n",
       "      <td>417.682979</td>\n",
       "      <td>48.105552</td>\n",
       "      <td>69.344740</td>\n",
       "      <td>91.475299</td>\n",
       "      <td>120.859143</td>\n",
       "      <td>1.433129</td>\n",
       "      <td>1.475024</td>\n",
       "      <td>1.499492</td>\n",
       "      <td>1.519377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  quantile ensemble      gcm    member     ssp  loc_intcp  loc_trend  \\\n",
       "0     main    LOCA2  CanESM5  r1i1p1f1  ssp585  57.742605   0.091815   \n",
       "1     q025    LOCA2  CanESM5  r1i1p1f1  ssp585  52.820643   0.015332   \n",
       "2     q975    LOCA2  CanESM5  r1i1p1f1  ssp585  63.460247   0.165027   \n",
       "\n",
       "   log_scale_intcp  log_scale_trend     shape  ...  100yr_return_level_2075  \\\n",
       "0         2.893627         0.001578 -0.226628  ...               247.453835   \n",
       "1         2.542673        -0.001818 -0.386558  ...               190.025593   \n",
       "2         3.173491         0.004790 -0.125098  ...               374.709258   \n",
       "\n",
       "   100yr_return_level_2100  10yr_return_level_diff_2075-1975  \\\n",
       "0               256.920751                         18.607240   \n",
       "1               189.973425                         -8.186143   \n",
       "2               417.682979                         48.105552   \n",
       "\n",
       "   25yr_return_level_diff_2075-1975  50yr_return_level_diff_2075-1975  \\\n",
       "0                         24.262965                         29.317828   \n",
       "1                        -14.267087                        -19.828523   \n",
       "2                         69.344740                         91.475299   \n",
       "\n",
       "   100yr_return_level_diff_2075-1975  10yr_return_level_chfc_2075-1975  \\\n",
       "0                          35.198942                          1.161544   \n",
       "1                         -25.490894                          0.934852   \n",
       "2                         120.859143                          1.433129   \n",
       "\n",
       "   25yr_return_level_chfc_2075-1975  50yr_return_level_chfc_2075-1975  \\\n",
       "0                          1.163637                          1.164849   \n",
       "1                          0.914075                          0.902574   \n",
       "2                          1.475024                          1.499492   \n",
       "\n",
       "   100yr_return_level_chfc_2075-1975  \n",
       "0                           1.165833  \n",
       "1                           0.893399  \n",
       "2                           1.519377  \n",
       "\n",
       "[3 rows x 46 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check\n",
    "gevcu.fit_gev_city(\n",
    "    city='boston',\n",
    "    metric_id='max_pr',\n",
    "    ensemble='LOCA2',\n",
    "    gcm='CanESM5',\n",
    "    ssp='ssp585',\n",
    "    member='r1i1p1f1',\n",
    "    fit_method='mle',\n",
    "    stationary=False,\n",
    "    nonstationary_scale=True,  # NEW: whether to fit non-stationary scale parameter\n",
    "    bootstrap=True,\n",
    "    n_boot_hist=1,\n",
    "    n_boot_proj=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d18e05d7-0c31-4d70-9198-ac2b9c96c99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/storage/group/pches/default/users/dcl5300/conus_comparison_lafferty-etal-2024/extreme_value/cities/original_grid/freq/boston_max_pr_1950-2100_mle_nonstat_nboot100_samples_scale.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5327e04-7935-4c55-a349-214a40f5b6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5038977538541212"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['ensemble'] == 'LOCA2') & (df['gcm'] == 'CanESM5') & (df['ssp'] == 'ssp585') & (df['member'] == 'r1i1p1f1')]['100yr_return_level_chfc_2075-1975'].quantile(0.975)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e44965b-c6d9-4ea6-998d-d06252293c05",
   "metadata": {},
   "source": [
    "## Bayesian GEV (old!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809ed003-bdb1-4a60-bed8-812a88a5f0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For Bayes\n",
    "# ############\n",
    "# ### Dask ###\n",
    "# ############\n",
    "# from dask_jobqueue import SLURMCluster\n",
    "\n",
    "# cluster = SLURMCluster(\n",
    "#     # account=\"pches\",\n",
    "#     account=\"open\",\n",
    "#     cores=3,\n",
    "#     processes=1,\n",
    "#     job_cpu=3,\n",
    "#     memory=\"3GiB\",\n",
    "#     walltime=\"12:00:00\",\n",
    "#     job_script_prologue=[\n",
    "#         f\"export PYTHONPATH={project_code_path}/.venv/lib/python3.12/site-packages:$PYTHONPATH\",  # Put venv first\n",
    "#         \"export JAX_PLATFORM_NAME=cpu\",\n",
    "#         \"export XLA_FLAGS='--xla_force_host_platform_device_count=1'\",\n",
    "#         # Force PyTensor to not use caching at all\n",
    "#         \"export PYTENSOR_FLAGS='cxx=,\",\n",
    "#         \"mode=FAST_COMPILE,\",  # Less aggressive optimization but more stable\n",
    "#         \"allow_gc=True,\",\n",
    "#         \"cache_size=0'\"        # Disable caching completely\n",
    "#     ],\n",
    "#     death_timeout=60,\n",
    "#     local_directory=\"/tmp\"\n",
    "# )\n",
    "\n",
    "# cluster.scale(5)\n",
    "\n",
    "# from dask.distributed import Client\n",
    "# client = Client(cluster)\n",
    "# client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47427ac9-69b6-4722-9ea8-7b986505d751",
   "metadata": {},
   "source": [
    "### Fit across ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf19267-0c3b-435c-bef8-d46e065c55e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Fit info: non-stationary\n",
    "future_years = [2015,2100]\n",
    "stationary = False\n",
    "return_periods = [100]\n",
    "\n",
    "# Parallelize with dask delayed\n",
    "delayed = []\n",
    "\n",
    "# Loop thorugh all combos\n",
    "for city in city_list.keys():\n",
    "    for metric_id in gev_metric_ids:\n",
    "        tmp = dask.delayed(gevbu.fit_bayesian_gev_ensemble)(\n",
    "            city=city,\n",
    "            metric_id=metric_id,\n",
    "            years=future_years,\n",
    "            stationary=stationary,\n",
    "            shape_sigma=0.2,\n",
    "            prior_identifier='shape_sigma_02',\n",
    "            return_periods=return_periods,\n",
    "        )\n",
    "        delayed.append(tmp)\n",
    "\n",
    "_ = dask.compute(*delayed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0a006b6-79fb-46cd-a127-632558337d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Fit info: stationary\n",
    "# hist_years = [1950,2014]\n",
    "# future_years = [2050,2100]\n",
    "# stationary = True\n",
    "# return_periods = [100]\n",
    "\n",
    "# # Parallelize with dask delayed\n",
    "# delayed = []\n",
    "\n",
    "# # Loop thorugh all combos\n",
    "# for city in city_list.keys():\n",
    "#     for metric_id in gev_metric_ids:\n",
    "#         for years in [hist_years, future_years]:\n",
    "#             tmp = dask.delayed(gevbu.fit_bayesian_gev_ensemble)(\n",
    "#                     city=city,\n",
    "#                     metric_id=metric_id,\n",
    "#                     years=years,\n",
    "#                     stationary=stationary,\n",
    "#                     return_periods=return_periods,\n",
    "#                     dask=False\n",
    "#             )\n",
    "#             delayed.append(tmp)\n",
    "\n",
    "# _ = dask.compute(*delayed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11ca430-4a39-4381-9cd1-5112a4ccc7b6",
   "metadata": {},
   "source": [
    "### Gather results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8da998a0-fb89-4e4a-9c1c-3364bfcb9e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 39s, sys: 11.7 s, total: 2min 51s\n",
      "Wall time: 15min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Loop thorugh all combos and store\n",
    "store_path = f\"{project_data_path}/extreme_value/cities/original_grid/bayes_combined/\"\n",
    "\n",
    "return_periods = [100]\n",
    "\n",
    "prior_identifier = \"shape_sigma_02\"\n",
    "\n",
    "stationary = False\n",
    "stationary_string = \"stat\" if stationary else \"nonstat\"\n",
    "\n",
    "# for city in city_list.keys():\n",
    "for city in ['nyc', 'chicago', 'denver']:\n",
    "    for metric_id in ['max_tasmax', 'max_pr', 'min_tasmin']:\n",
    "    # for metric_id in gev_metric_ids:\n",
    "        for years in [None, [2015,2100]]:\n",
    "            # Check if done\n",
    "            change_identifier = \"\" if years is None else f\"_change_{years[0]}-{years[1]}\"\n",
    "            file_path = f\"{store_path}/{city}_{metric_id}_{stationary_string}_{prior_identifier}{change_identifier}.csv\"\n",
    "            if os.path.exists(file_path):\n",
    "                continue\n",
    "            # Read\n",
    "            df = gevbu.gather_bayesian_gev_results_all(\n",
    "                city = city,\n",
    "                metric_id = metric_id,\n",
    "                return_periods = return_periods,\n",
    "                stationary = stationary,\n",
    "                prior_identifier = prior_identifier,\n",
    "                years = years,\n",
    "            )\n",
    "            # Store\n",
    "            df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417d30a0-9223-4810-88a7-61dad1926833",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
