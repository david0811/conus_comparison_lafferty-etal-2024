{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4054ed6-6ef0-4bee-8356-9ac60120c037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import dask\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "from utils import city_list\n",
    "import metric_funcs as mf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d8e6ce-cb21-48ba-a25f-4b8e3ba2dae4",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "771cf861-108d-464d-9330-56aa2e734125",
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "#### Paths #####\n",
    "################\n",
    "# Update these for reproduction\n",
    "\n",
    "project_data_path = \"/storage/group/pches/default/users/dcl5300/conus_comparison_lafferty-etal-2024/\"\n",
    "project_code_path = \"/storage/home/dcl5300/work/current_projects/conus_comparison_lafferty-etal-2024/\"\n",
    "loca_path = \"/storage/group/pches/default/public/LOCA2\" # raw loca outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35122b6b-92dc-4124-af47-470e7ad9ee6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "### Models ###\n",
    "##############\n",
    "\n",
    "gcms = os.listdir(f\"{loca_path}/\")\n",
    "gcms.remove('training_data')\n",
    "gcms.remove('scripts')\n",
    "\n",
    "loca_all = {}\n",
    "\n",
    "# Loop through gcms\n",
    "for gcm in gcms:\n",
    "    loca_all[gcm] = {}\n",
    "    # Loop through members\n",
    "    members = os.listdir(f\"{loca_path}/{gcm}/0p0625deg/\")\n",
    "    for member in members:\n",
    "        # Append SSPs\n",
    "        ssps = os.listdir(f\"{loca_path}/{gcm}/0p0625deg/{member}/\")\n",
    "        loca_all[gcm][member] = ssps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4a8b04a-29da-4392-8400-175d6eedf4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# gcm: 27\n",
      "# gcm/expts: 99\n",
      "# gcm/expts/ens: 329\n"
     ]
    }
   ],
   "source": [
    "##############\n",
    "### Models ###\n",
    "##############\n",
    "\n",
    "# Matches website (https://loca.ucsd.edu/loca-version-2-for-north-america-ca-jan-2023/) as of Jan 2023\n",
    "print(f\"# gcm: {len(gcms)}\")\n",
    "print(f\"# gcm/expts: {np.sum([len(np.unique([item for row in [loca_all[gcm][member] for member in loca_all[gcm].keys()] for item in row])) for gcm in gcms])}\")\n",
    "print(f\"# gcm/expts/ens: {np.sum([len(loca_all[gcm][ssp]) for gcm in gcms for ssp in loca_all[gcm]])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d6d6258-4df4-45f6-9f4f-30c6c423c30f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-743ac772-9575-11ef-94eb-149ecfe7a7c9</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> dask_jobqueue.SLURMCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"/proxy/8787/status\" target=\"_blank\">/proxy/8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <button style=\"margin-bottom: 12px;\" data-commandlinker-command=\"dask:populate-and-launch-layout\" data-commandlinker-args='{\"url\": \"/proxy/8787/status\" }'>\n",
       "                Launch dashboard in JupyterLab\n",
       "            </button>\n",
       "        \n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">SLURMCluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">1c1fbe5b</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"/proxy/8787/status\" target=\"_blank\">/proxy/8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 0\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 0\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 0 B\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-8efd8a1b-5d06-479b-bbe2-994bdb9fb562</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://10.6.8.19:37907\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"/proxy/8787/status\" target=\"_blank\">/proxy/8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 0 B\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.6.8.19:37907' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 17:55:12,758 - distributed.batched - INFO - Batched Comm Closed <TCP (closed)  local=tcp://10.6.8.19:37907 remote=tcp://10.6.8.19:33174>\n",
      "Traceback (most recent call last):\n",
      "  File \"/storage/home/dcl5300/miniforge3/envs/climate-stack-2024-10/lib/python3.12/site-packages/distributed/batched.py\", line 115, in _background_send\n",
      "    nbytes = yield coro\n",
      "             ^^^^^^^^^^\n",
      "  File \"/storage/home/dcl5300/miniforge3/envs/climate-stack-2024-10/lib/python3.12/site-packages/tornado/gen.py\", line 766, in run\n",
      "    value = future.result()\n",
      "            ^^^^^^^^^^^^^^^\n",
      "  File \"/storage/home/dcl5300/miniforge3/envs/climate-stack-2024-10/lib/python3.12/site-packages/distributed/comm/tcp.py\", line 262, in write\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "### Dask ###\n",
    "############\n",
    "from dask_jobqueue import SLURMCluster\n",
    "\n",
    "cluster = SLURMCluster(\n",
    "    # account=\"pches\",\n",
    "    account=\"open\",\n",
    "    cores=1,\n",
    "    memory=\"20GiB\",\n",
    "    walltime=\"06:00:00\"\n",
    ")\n",
    "\n",
    "cluster.scale(jobs=30)  # ask for jobs\n",
    "\n",
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(cluster)\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d589149-34f5-4733-91bc-43581cc52b88",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53668a26-60e8-4c2e-a0c8-52546707ff0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## File path function\n",
    "def make_loca_file_path(loca_path, gcm, member, ssp, var):\n",
    "    \"\"\"\n",
    "    Returns list of file paths for a given downscaled LOCA output.\n",
    "    \"\"\"\n",
    "    out_path = f\"{loca_path}/{gcm}/0p0625deg/{member}/{ssp}/{var}\"\n",
    "\n",
    "    if os.path.isdir(out_path):\n",
    "         # Take latest version if possible\n",
    "        files = glob(f\"{out_path}/*_v2024*\")\n",
    "        # Check earlier version if empty\n",
    "        if len(files) == 0:\n",
    "            files = glob(f\"{out_path}/*_v2022*\")\n",
    "            \n",
    "        return files\n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "## Unit conversion\n",
    "def convert_units(ds):\n",
    "    # Convert units\n",
    "    for var in ds.keys():\n",
    "        if ds[var].attrs['units'] == 'K':\n",
    "            ds[var] = ds[var] - 273.15    \n",
    "            ds[var].attrs[\"units\"] = 'C'\n",
    "        elif ds[var].attrs['units'] == 'kg m-2 s-1':\n",
    "            ds[var] = ds[var] * 86400\n",
    "            ds[var].attrs[\"units\"] = 'mm/day'\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08ab8e17-ee65-407d-bd8b-fe64a1ac2149",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# Metric calulcation function #\n",
    "###############################\n",
    "def calculate_metric(metric_func, var_id, needed_vars, gcm, member, ssp, loca_path, out_path):\n",
    "    \"\"\"\n",
    "    Inputs: selected gcm, member, ssp, variable, and metric to calculate (from LOCA)\n",
    "    Outputs: calculated (annual) metric\n",
    "    \"\"\" \n",
    "    # Get all file paths\n",
    "    files = {}\n",
    "    for var in needed_vars:\n",
    "        files[var] = make_loca_file_path(loca_path, gcm, member, ssp, var)\n",
    "        \n",
    "    # Loop through LOCA2 time slices\n",
    "    if ssp == \"historical\":\n",
    "        time_slices = [\"1950-2014\"]\n",
    "    else:\n",
    "        time_slices = [\"2015-2044\", \"2045-2074\", \"2075-2100\"]\n",
    "        \n",
    "    for time_slice in time_slices:\n",
    "        try:\n",
    "            # Check if done\n",
    "            save_path = out_path.replace('.nc', f'_{time_slice}.nc')\n",
    "            if os.path.isfile(save_path):\n",
    "                return None\n",
    "            # Load\n",
    "            files_to_load = [xr.open_dataset(file, chunks='auto') for var in needed_vars for file in files[var] if time_slice in file]\n",
    "            ds_in = xr.merge(files_to_load, combine_attrs='drop_conflicts')\n",
    "            # Convert units\n",
    "            ds_in = convert_units(ds_in)\n",
    "        \n",
    "            # Calculate metric\n",
    "            ds_out = metric_func(ds_in, var_id)\n",
    "    \n",
    "            # Store\n",
    "            ds_out.to_netcdf(out_path.replace('.nc', f'_{time_slice}.nc'))\n",
    "            \n",
    "        # Log if error\n",
    "        except Exception as e:\n",
    "            except_path = f\"{project_code_path}/code/logs\"\n",
    "            with open(f\"{except_path}/{gcm}_{member}_{ssp}_{var_id}_{time_slice}_LOCA.txt\", \"w\") as f:\n",
    "                f.write(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa93b14a-9413-4e9a-b508-596d9f2e7701",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.5 s, sys: 1.68 s, total: 21.2 s\n",
      "Wall time: 4min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#########################\n",
    "## Cooling Degree Days ##\n",
    "#########################\n",
    "var_id = \"cdd\"\n",
    "metric_func = mf.calculate_dd\n",
    "needed_vars = ['tasmin', 'tasmax']\n",
    "\n",
    "out_path = lambda gcm, ssp, member: f\"{project_data_path}/metrics/LOCA2/{var_id}_{gcm}_{member}_{ssp}.nc\"\n",
    "\n",
    "# Parallelize over dask delayed\n",
    "delayed = []\n",
    "\n",
    "# Loop through gcms\n",
    "for gcm in gcms:\n",
    "    # Loop through members\n",
    "    for member in loca_all[gcm].keys():\n",
    "        # Loop through SSPs\n",
    "        for ssp in loca_all[gcm][member]:\n",
    "            # Calculate metric\n",
    "            calculate_metric(metric_func = metric_func,\n",
    "                             var_id = var_id,\n",
    "                             gcm = gcm,\n",
    "                             ssp = ssp,\n",
    "                             member=member,\n",
    "                             needed_vars = needed_vars,\n",
    "                             loca_path = loca_path,\n",
    "                             out_path = out_path(gcm, ssp, member))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be290303-3555-40bb-9576-1c8164c4d041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13 s, sys: 978 ms, total: 14 s\n",
      "Wall time: 3min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#########################\n",
    "## Heating Degree Days ##\n",
    "#########################\n",
    "var_id = \"hdd\"\n",
    "metric_func = mf.calculate_dd\n",
    "needed_vars = ['tasmin', 'tasmax']\n",
    "\n",
    "out_path = lambda gcm, ssp, member: f\"{project_data_path}/metrics/LOCA2/{var_id}_{gcm}_{member}_{ssp}.nc\"\n",
    "\n",
    "# Parallelize over dask delayed\n",
    "delayed = []\n",
    "\n",
    "# Loop through gcms\n",
    "for gcm in gcms:\n",
    "    # Loop through members\n",
    "    for member in loca_all[gcm].keys():\n",
    "        # Loop through SSPs\n",
    "        for ssp in loca_all[gcm][member]:\n",
    "            # Calculate metric\n",
    "            calculate_metric(metric_func = metric_func,\n",
    "                             var_id = var_id,\n",
    "                             gcm = gcm,\n",
    "                             ssp = ssp,\n",
    "                             member=member,\n",
    "                             needed_vars = needed_vars,\n",
    "                             loca_path = loca_path,\n",
    "                             out_path = out_path(gcm, ssp, member))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "323103d9-bcb2-4818-b152-2c0d7b1cc643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.3 s, sys: 962 ms, total: 13.3 s\n",
      "Wall time: 2min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#########################\n",
    "## Average Temperature ##\n",
    "#########################\n",
    "var_id = \"tas\"\n",
    "metric_func = mf.calculate_avg\n",
    "needed_vars = ['tasmin', 'tasmax']\n",
    "\n",
    "out_path = lambda gcm, ssp, member: f\"{project_data_path}/metrics/LOCA2/avg_{var_id}_{gcm}_{member}_{ssp}.nc\"\n",
    "\n",
    "# Parallelize over dask delayed\n",
    "delayed = []\n",
    "\n",
    "# Loop through gcms\n",
    "for gcm in gcms:\n",
    "    # Loop through members\n",
    "    for member in loca_all[gcm].keys():\n",
    "        # Loop through SSPs\n",
    "        for ssp in loca_all[gcm][member]:\n",
    "            # Calculate metric\n",
    "            calculate_metric(metric_func = metric_func,\n",
    "                             var_id = var_id,\n",
    "                             gcm = gcm,\n",
    "                             ssp = ssp,\n",
    "                             member=member,\n",
    "                             needed_vars = needed_vars,\n",
    "                             loca_path = loca_path,\n",
    "                             out_path = out_path(gcm, ssp, member))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b372ced-7e4e-4c31-8483-93bc4a8b206c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.1 s, sys: 747 ms, total: 10.9 s\n",
      "Wall time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#########################\n",
    "## Maximum Temperature ##\n",
    "#########################\n",
    "var_id = \"tasmax\"\n",
    "metric_func = mf.calculate_max\n",
    "needed_vars = ['tasmax']\n",
    "\n",
    "out_path = lambda gcm, ssp, member: f\"{project_data_path}/metrics/LOCA2/max_{var_id}_{gcm}_{member}_{ssp}.nc\"\n",
    "\n",
    "# Parallelize over dask delayed\n",
    "delayed = []\n",
    "\n",
    "# Loop through gcms\n",
    "for gcm in gcms:\n",
    "    # Loop through members\n",
    "    for member in loca_all[gcm].keys():\n",
    "        # Loop through SSPs\n",
    "        for ssp in loca_all[gcm][member]:\n",
    "            # Calculate metric\n",
    "            calculate_metric(metric_func = metric_func,\n",
    "                             var_id = var_id,\n",
    "                             gcm = gcm,\n",
    "                             ssp = ssp,\n",
    "                             member=member,\n",
    "                             needed_vars = needed_vars,\n",
    "                             loca_path = loca_path,\n",
    "                             out_path = out_path(gcm, ssp, member))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "109bf0a4-8f05-4cfd-b7ab-c900cbd78de1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.6 s, sys: 713 ms, total: 11.3 s\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#########################\n",
    "## Minimum Temperature ##\n",
    "#########################\n",
    "var_id = \"tasmin\"\n",
    "metric_func = mf.calculate_min\n",
    "needed_vars = ['tasmin']\n",
    "\n",
    "out_path = lambda gcm, ssp, member: f\"{project_data_path}/metrics/LOCA2/min_{var_id}_{gcm}_{member}_{ssp}.nc\"\n",
    "\n",
    "# Parallelize over dask delayed\n",
    "delayed = []\n",
    "\n",
    "# Loop through gcms\n",
    "for gcm in gcms:\n",
    "    # Loop through members\n",
    "    for member in loca_all[gcm].keys():\n",
    "        # Loop through SSPs\n",
    "        for ssp in loca_all[gcm][member]:\n",
    "            # Calculate metric\n",
    "            calculate_metric(metric_func = metric_func,\n",
    "                             var_id = var_id,\n",
    "                             gcm = gcm,\n",
    "                             ssp = ssp,\n",
    "                             member=member,\n",
    "                             needed_vars = needed_vars,\n",
    "                             loca_path = loca_path,\n",
    "                             out_path = out_path(gcm, ssp, member))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3d58eea-bcc4-4dba-847d-fb7d30085237",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 68 ms, sys: 61.8 ms, total: 130 ms\n",
      "Wall time: 1.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#########################\n",
    "## Maximum Precip ##\n",
    "#########################\n",
    "var_id = \"pr\"\n",
    "metric_func = mf.calculate_max\n",
    "needed_vars = ['pr']\n",
    "\n",
    "out_path = lambda gcm, ssp, member: f\"{project_data_path}/metrics/LOCA2/max_{var_id}_{gcm}_{member}_{ssp}.nc\"\n",
    "\n",
    "# Parallelize over dask delayed\n",
    "delayed = []\n",
    "\n",
    "# Loop through gcms\n",
    "for gcm in gcms:\n",
    "    # Loop through members\n",
    "    for member in loca_all[gcm].keys():\n",
    "        # Loop through SSPs\n",
    "        for ssp in loca_all[gcm][member]:\n",
    "            # Calculate metric\n",
    "            calculate_metric(metric_func = metric_func,\n",
    "                             var_id = var_id,\n",
    "                             gcm = gcm,\n",
    "                             ssp = ssp,\n",
    "                             member=member,\n",
    "                             needed_vars = needed_vars,\n",
    "                             loca_path = loca_path,\n",
    "                             out_path = out_path(gcm, ssp, member))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b42e89a5-8366-41ef-a8fa-4490c7fa3d80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.8 ms, sys: 30.7 ms, total: 56.5 ms\n",
      "Wall time: 335 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "################\n",
    "## Sum Precip ##\n",
    "################\n",
    "var_id = \"pr\"\n",
    "metric_func = mf.calculate_sum\n",
    "needed_vars = ['pr']\n",
    "\n",
    "out_path = lambda gcm, ssp, member: f\"{project_data_path}/metrics/LOCA2/sum_{var_id}_{gcm}_{member}_{ssp}.nc\"\n",
    "\n",
    "# Parallelize over dask delayed\n",
    "delayed = []\n",
    "\n",
    "# Loop through gcms\n",
    "for gcm in gcms:\n",
    "    # Loop through members\n",
    "    for member in loca_all[gcm].keys():\n",
    "        # Loop through SSPs\n",
    "        for ssp in loca_all[gcm][member]:\n",
    "            # Calculate metric\n",
    "            calculate_metric(metric_func = metric_func,\n",
    "                             var_id = var_id,\n",
    "                             gcm = gcm,\n",
    "                             ssp = ssp,\n",
    "                             member=member,\n",
    "                             needed_vars = needed_vars,\n",
    "                             loca_path = loca_path,\n",
    "                             out_path = out_path(gcm, ssp, member))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62ddfd14-3731-4add-976d-c3948ad68ca3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c8eec1-f087-4845-bad5-d1e6b77dba17",
   "metadata": {},
   "source": [
    "# Summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4995933f-220f-41e8-a1bd-1533e2ad182c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a78296ed-e9c1-4577-9d4a-1ac0ddd63780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple preprocessing function to add model and year coordinates\n",
    "def _preprocess(ds):\n",
    "    # Add model coordinate\n",
    "    model = ds.encoding['source'].split('/')[-1].split('.')[1]\n",
    "    ds = ds.assign_coords(model = model)\n",
    "\n",
    "    # Add member\n",
    "    member = ds.encoding['source'].split('/')[-1].split('.')[3]\n",
    "    ds = ds.assign_coords(member = member)\n",
    "\n",
    "    # Time -> year\n",
    "    ds['time'] = ds['time'].dt.year\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dd7c3f2-c956-43a5-bb25-ec5118be150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates summary indices for CIL-GDPCIR ensemble for given SSP\n",
    "def get_summary_indices(metric_id, ssp, years, out_path, out_str):\n",
    "    \"\"\"\n",
    "    Current summary indices calculated: mean, 99th quantile, 99% quantile range\n",
    "    `years` define the window over which all outputs are pooled. \n",
    "    \"\"\"\n",
    "    # Check if done\n",
    "    if not os.path.isfile(f\"{out_path}/{out_str}.nc\"):\n",
    "        # Read\n",
    "        ds_models = []\n",
    "        for model in models:\n",
    "            files = glob(f\"{project_data_path}/metrics/LOCA2/{metric_id}.{model}.{ssp}.r*.nc\")\n",
    "            # Check files exist\n",
    "            if len(files) > 0:\n",
    "                ds_members = []\n",
    "                # Read all members\n",
    "                for member in loca_all[model].keys():\n",
    "                    if len(glob(f\"{project_data_path}/metrics/LOCA2/{metric_id}.{model}.{ssp}.{member}.*.nc\")) > 0:\n",
    "                        try:\n",
    "                            ds_tmp = xr.open_mfdataset(f\"{project_data_path}/metrics/LOCA2/{metric_id}.{model}.{ssp}.{member}.*.nc\",\n",
    "                                                       preprocess=_preprocess)\n",
    "                            ds_members.append(ds_tmp)\n",
    "                        except Exception as e:\n",
    "                            except_path = f\"{project_code_path}/code/logs\"\n",
    "                            with open(f\"{except_path}/{model}_{member}_{ssp}_{metric_id}_LOCA.txt\", \"w\") as f:\n",
    "                                f.write(str(e))\n",
    "            # Combine & append members\n",
    "            ds_models.append(xr.concat(ds_members, dim=\"member\", fill_value=np.nan))\n",
    "        # Combine models\n",
    "        ds = xr.concat(ds_models, dim=\"model\", fill_value=np.nan)\n",
    "\n",
    "        # Rename\n",
    "        ds = ds.rename({list(ds.data_vars)[0]: metric_id})\n",
    "\n",
    "        # Time slice\n",
    "        ds_sel = ds.sel(time=slice(years[0],years[1]))#.chunk(dict(model=-1, time=-1, member=-1, lat=50, lon=100))\n",
    "    \n",
    "        ## Summary indices\n",
    "        # Mean\n",
    "        ds_mean = ds_sel.mean(dim=['model', 'time', 'member']).assign_coords(indice = 'mean')\n",
    "        # Quantiles\n",
    "        ds_qlow = ds_sel.quantile(0.005, dim=['model', 'time', 'member'])\n",
    "        ds_qhigh = ds_sel.quantile(0.995, dim=['model', 'time', 'member'])\n",
    "        ds_qrange = (ds_qhigh - ds_qlow).assign_coords(indice = '99range')\n",
    "    \n",
    "        ds_q99 = ds_sel.quantile(0.99, dim=['model', 'time', 'member']).assign_coords(indice = 'q99')\n",
    "\n",
    "        # Store\n",
    "        ds_out = xr.concat([ds_mean, ds_qrange, ds_q99], dim='indice')\n",
    "        ds_out.to_netcdf(f\"{out_path}/{out_str}.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0636ff2b-c65c-462c-b1db-815061d820f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for years in [[2020,2040], [2050,2070], [2080,2100]]:\n",
    "    for ssp in ['ssp245', 'ssp370', 'ssp585']:\n",
    "        for metric_id in ['avg_tas', 'sum_pr', 'max_tasmax', 'max_pr', 'max_tas']:\n",
    "            get_summary_indices(metric_id = metric_id,\n",
    "                                ssp = ssp,\n",
    "                                years = years,\n",
    "                                out_path=f\"{project_data_path}/summary_indices\",\n",
    "                                out_str=f\"LOCA2_{ssp}_{str(years[0])}-{str(years[1])}_{metric_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e342c0-0a41-4830-8594-f4135db19b13",
   "metadata": {},
   "source": [
    "## Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a36193b8-c6cf-4982-b714-fd27026632d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculates summary indices for CIL-GDPCIR ensemble for given SSP\n",
    "def get_raw_data(metric, ssp, years, lat, lon, out_path, out_str):\n",
    "    \"\"\"\n",
    "    Current summary indices calculated: mean, 99th quantile, 99% quantile range\n",
    "    `years` define the window over which all outputs are pooled. \n",
    "    \"\"\"\n",
    "    def read_and_process(metric, model, member, ssp, years, lat, lon):\n",
    "        # Read\n",
    "        files = glob(f\"{project_data_path}/metrics/LOCA2/{metric}.{model}.{ssp}.{member}.*.nc\")\n",
    "        ds_tmp = xr.concat([xr.open_dataset(file) for file in files], dim='time')\n",
    "        ds_tmp['time'] = ds_tmp[\"time\"].dt.year\n",
    "        \n",
    "        # Rename\n",
    "        ds_tmp = ds_tmp.rename({list(ds_tmp.data_vars)[0]: metric})\n",
    "\n",
    "        # Time slice\n",
    "        if years is not None:\n",
    "            ds_sel = ds_tmp.sel(time=slice(years[0],years[1]))\n",
    "        else:\n",
    "            ds_sel = ds_tmp.copy()\n",
    "    \n",
    "        # Location selection\n",
    "        if lon < 0:\n",
    "            lon = 360 + lon\n",
    "        ds_sel = ds_sel.sel(lat=lat, lon=lon, method='nearest')\n",
    "        \n",
    "        # Construct dataframe\n",
    "        df_tmp = ds_sel.to_dataframe().dropna().drop(columns=[\"lat\", \"lon\"]).reset_index()\n",
    "        df_tmp[\"ssp\"] = ssp\n",
    "        df_tmp[\"model\"] = model\n",
    "        df_tmp[\"member\"] = member\n",
    "\n",
    "        # Return \n",
    "        return df_tmp\n",
    "\n",
    "    # Check if done\n",
    "    if not os.path.isfile(f\"{out_path}/{out_str}.csv\"):\n",
    "        df_delayed = []\n",
    "        # Loop through models\n",
    "        for model in models:\n",
    "            # Loop through members\n",
    "            for member in loca_all[model].keys():\n",
    "                # Some missing combinations as reported above\n",
    "                check = glob(f\"{project_data_path}/metrics/LOCA2/{metric}.{model}.{ssp}.{member}.*.nc\")\n",
    "                if len(check) > 0:\n",
    "                    df_tmp = dask.delayed(read_and_process)(metric, model, member, ssp, years, lat, lon)\n",
    "                    df_delayed.append(df_tmp)\n",
    "        \n",
    "        # Compute and store\n",
    "        df_out = dask.compute(*df_delayed)\n",
    "        pd.concat(df_out).to_csv(f\"{out_path}/{out_str}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba4aebd-dfd9-4ae3-9ee5-cdbe0a26d6b4",
   "metadata": {},
   "source": [
    "### Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3b3deea-fe60-4085-9109-38193861fc6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 2s, sys: 8.31 s, total: 1min 10s\n",
      "Wall time: 8min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for city in ['chicago', 'nyc', 'denver']:\n",
    "    lat, lon = city_list[city]\n",
    "    for ssp in ['ssp245', 'ssp370', 'ssp585']:\n",
    "        for metric in ['avg_tas', 'sum_pr', 'max_tasmax', 'max_pr', 'max_tas']:\n",
    "            get_raw_data(metric = metric,\n",
    "                         ssp = ssp,\n",
    "                         years = None,\n",
    "                         lat = lat,\n",
    "                         lon = lon,\n",
    "                         out_path=f\"{project_data_path}/summary_raw_original_grid/\",\n",
    "                         out_str=f\"{city}_LOCA2_{ssp}_{metric}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5388d169-2f3d-4bdf-8e75-75c22718d622",
   "metadata": {},
   "source": [
    "### Regridded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82f0e07-87fa-4d57-94c4-cc25871a610e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for city in city_list.keys():\n",
    "    lat, lon = city_list[city]\n",
    "    for years in [[2020,2040], [2050,2070], [2080,2100]]:\n",
    "        for ssp in ['ssp245', 'ssp370', 'ssp585']:\n",
    "            for metric in ['avg_tas', 'sum_pr', 'max_tasmax', 'max_pr', 'max_tas']:\n",
    "                get_raw_data(metric = metric,\n",
    "                             ssp = ssp,\n",
    "                             years = years,\n",
    "                             lat = lat,\n",
    "                             lon = lon,\n",
    "                             out_path=f\"{project_data_path}/summary_raw\",\n",
    "                             out_str=f\"{city}_LOCA2_{ssp}_{str(years[0])}-{str(years[1])}_{metric}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933f4975-5c26-4d3d-bb62-88812be5eb3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
